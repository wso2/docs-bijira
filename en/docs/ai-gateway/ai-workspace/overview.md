# AI Workspace Overview

The AI Workspace is a comprehensive platform for managing AI services, including LLM providers, proxy configurations, and Model Context Protocol (MCP) integrations.

## LLM Providers

Connect to various LLM service providers and manage their configurations:

- **Connect OpenAI, Anthropic, and more**: Integrate multiple AI service providers
- **Manage provider credentials**: Securely store and manage API keys and authentication
- **Monitor provider status**: Track the availability and health of connected providers

Learn more in the [LLM Providers](llm-providers/overview.md) section.

## LLM Proxies

Create and manage proxy endpoints for your LLM services:

- **Create proxy endpoints**: Set up endpoints for routing AI requests
- **Attach policies and guardrails**: Apply rate limiting, content filtering, and security policies
- **Track proxy traffic**: Monitor usage and performance metrics

Learn more in the [LLM Proxies](llm-proxies/overview.md) section.

## MCP Features (Coming Soon)

Model Context Protocol (MCP) External Servers and Registries will be available soon.
